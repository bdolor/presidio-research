{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from presidio_evaluator.data_generator.main import generate,read_synth_dataset\n",
    "\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate fake PII data using Presidio's data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presidio's data generator allows you to generate a synthetic dataset with two preriquisites:\n",
    "1. A fake PII csv (We used https://www.fakenamegenerator.com/)\n",
    "2. A text file with template sentences or paragraphs. In this file, each PII entity placeholder is written in brackets. The name of the PII entity should be one of the columns in the fake PII csv file.\n",
    "\n",
    "The generator creates fake sentences based on the provided fake PII csv AND a list of [extension functions](../presidio_evaluator/data_generator/extensions.py) and a few additional 3rd party libraries like `Faker`, and `haikunator`.\n",
    "\n",
    "\n",
    "For example:\n",
    "1. **A fake PII csv**:\n",
    "\n",
    "| FIRST_NAME  |  LAST_NAME  |  EMAIL |\n",
    "|-------------|-------------|-----------|\n",
    "| David       |  Brown      |  david.brown@jobhop.com |\n",
    "| Mel         |  Brown      |  melb@hobjob.com |\n",
    "\n",
    "\n",
    "2. **Templates**:\n",
    "\n",
    "My name is [FIRST_NAME]\n",
    "\n",
    "You can email me at [EMAIL]. Thanks, [FIRST_NAME]\n",
    "\n",
    "What's your last name? It's [LAST_NAME]\n",
    "\n",
    "Every time I see you falling I get down on my knees and pray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate files\n",
    "Based on these two prerequisites, a requested number of examples and an output file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Warning: Dictionary path not provided. Feature `is_in_vocabulary` will be set to False for all samples\n",
      "Preparing sample sentences for ingestion\n",
      "Preparing fake PII data for ingestion\n",
      "Generating address parts\n",
      "Generating roles\n",
      "Generating titles\n",
      "Generating nationalities\n",
      "Generating IBANs\n",
      "Generating company names\n",
      "Finished preparing fake PII data\n",
      "loading model en_core_web_lg\n",
      "Warning: entity URL is in the templates but not in the PII dataset. Ignoring.\n",
      "Warning: entity URL is in the templates but not in the PII dataset. Ignoring.\n",
      "Warning: entity US_SSN is in the templates but not in the PII dataset. Ignoring.\n",
      "Warning: entity URL is in the templates but not in the PII dataset. Ignoring.\n",
      "generated 100 examples\n",
      "Finished creating generated dataset. File location:../data/generated_size_100_date_March_08_2020.json\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.34it/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "EXAMPLES = 100\n",
    "SPAN_TO_TAG = True #Whether to create tokens + token labels (tags)\n",
    "TEMPLATES_FILE = '../presidio_evaluator/data_generator/' \\\n",
    "                 'raw_data/templates.txt'\n",
    "KEEP_ONLY_TAGGED = False\n",
    "LOWER_CASE_RATIO = 0.1\n",
    "IGNORE_TYPES = {\"IP_ADDRESS\", 'US_SSN', 'URL'}\n",
    "\n",
    "cur_time = datetime.date.today().strftime(\"%B_%d_%Y\")\n",
    "\n",
    "OUTPUT = \"../data/generated_size_{}_date_{}.json\".format(EXAMPLES, cur_time)\n",
    "\n",
    "fake_pii_csv = '../presidio_evaluator/data_generator/' \\\n",
    "               'raw_data/FakeNameGenerator.com_3000.csv'\n",
    "utterances_file = TEMPLATES_FILE\n",
    "dictionary_path = None\n",
    "\n",
    "examples = generate(fake_pii_csv=fake_pii_csv,\n",
    "                        utterances_file=utterances_file,\n",
    "                        dictionary_path=dictionary_path,\n",
    "                        output_file=OUTPUT,\n",
    "                        lower_case_ratio=LOWER_CASE_RATIO,\n",
    "                        num_of_examples=EXAMPLES,\n",
    "                        ignore_types=IGNORE_TYPES,\n",
    "                        keep_only_tagged=KEEP_ONLY_TAGGED,\n",
    "                        span_to_tag=SPAN_TO_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read a dataset file into the InputSample format, use `read_synth_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "input_samples = read_synth_dataset(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Full text: Stm Auto Parts is the brainchild of our 3 founders: Hanna Mattila, Royale Moïse and Emmie Ström.  The idea was born (on the beach) while they were constructing a website to be the basis of another start-up idea.\nSpans: [Type: ORGANIZATION, value: Stm Auto Parts, start: 0, end: 14, Type: PERSON, value: Hanna Mattila, start: 52, end: 65, Type: PERSON, value: Royale Moïse, start: 67, end: 79, Type: PERSON, value: Emmie Ström, start: 84, end: 95]\nTokens: [Stm, Auto, Parts, is, the, brainchild, of, our, 3, founders, :, Hanna, Mattila, ,, Royale, Moïse, and, Emmie, Ström, .,  , The, idea, was, born, (, on, the, beach, ), while, they, were, constructing, a, website, to, be, the, basis, of, another, start, -, up, idea, .]\nTags: ['B-ORGANIZATION', 'I-ORGANIZATION', 'L-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'L-PERSON', 'O', 'B-PERSON', 'L-PERSON', 'O', 'B-PERSON', 'L-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "input_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full structure of each input_sample is the following. It includes different feature values per token as calculated by Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'full_text': 'Stm Auto Parts is the brainchild of our 3 founders: Hanna Mattila, Royale Moïse and Emmie Ström.  The idea was born (on the beach) while they were constructing a website to be the basis of another start-up idea.',\n 'masked': None,\n 'spans': [{'entity_type': 'ORGANIZATION',\n   'entity_value': 'Stm Auto Parts',\n   'start_position': 0,\n   'end_position': 14},\n  {'entity_type': 'PERSON',\n   'entity_value': 'Hanna Mattila',\n   'start_position': 52,\n   'end_position': 65},\n  {'entity_type': 'PERSON',\n   'entity_value': 'Royale Moïse',\n   'start_position': 67,\n   'end_position': 79},\n  {'entity_type': 'PERSON',\n   'entity_value': 'Emmie Ström',\n   'start_position': 84,\n   'end_position': 95}],\n 'tokens': [{'text': 'Stm',\n   'idx': 0,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'compound',\n   'lemma_': 'Stm',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Auto',\n   'idx': 4,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'compound',\n   'lemma_': 'Auto',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Parts',\n   'idx': 9,\n   'tag_': 'NNPS',\n   'pos_': 'PROPN',\n   'dep_': 'nsubj',\n   'lemma_': 'Parts',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'is',\n   'idx': 15,\n   'tag_': 'VBZ',\n   'pos_': 'AUX',\n   'dep_': 'ROOT',\n   'lemma_': 'be',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'the',\n   'idx': 18,\n   'tag_': 'DT',\n   'pos_': 'DET',\n   'dep_': 'det',\n   'lemma_': 'the',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'brainchild',\n   'idx': 22,\n   'tag_': 'NN',\n   'pos_': 'NOUN',\n   'dep_': 'attr',\n   'lemma_': 'brainchild',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'of',\n   'idx': 33,\n   'tag_': 'IN',\n   'pos_': 'ADP',\n   'dep_': 'prep',\n   'lemma_': 'of',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'our',\n   'idx': 36,\n   'tag_': 'PRP$',\n   'pos_': 'DET',\n   'dep_': 'poss',\n   'lemma_': '-PRON-',\n   '_': {'is_in_vocabulary': False}},\n  {'text': '3',\n   'idx': 40,\n   'tag_': 'CD',\n   'pos_': 'NUM',\n   'dep_': 'nummod',\n   'lemma_': '3',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'founders',\n   'idx': 42,\n   'tag_': 'NNS',\n   'pos_': 'NOUN',\n   'dep_': 'pobj',\n   'lemma_': 'founder',\n   '_': {'is_in_vocabulary': False}},\n  {'text': ':',\n   'idx': 50,\n   'tag_': ':',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': ':',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Hanna',\n   'idx': 52,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'compound',\n   'lemma_': 'Hanna',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Mattila',\n   'idx': 58,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'appos',\n   'lemma_': 'Mattila',\n   '_': {'is_in_vocabulary': False}},\n  {'text': ',',\n   'idx': 65,\n   'tag_': ',',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': ',',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Royale',\n   'idx': 67,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'compound',\n   'lemma_': 'Royale',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Moïse',\n   'idx': 74,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'conj',\n   'lemma_': 'Moïse',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'and',\n   'idx': 80,\n   'tag_': 'CC',\n   'pos_': 'CCONJ',\n   'dep_': 'cc',\n   'lemma_': 'and',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Emmie',\n   'idx': 84,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'compound',\n   'lemma_': 'Emmie',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'Ström',\n   'idx': 90,\n   'tag_': 'NNP',\n   'pos_': 'PROPN',\n   'dep_': 'conj',\n   'lemma_': 'Ström',\n   '_': {'is_in_vocabulary': False}},\n  {'text': '.',\n   'idx': 95,\n   'tag_': '.',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': '.',\n   '_': {'is_in_vocabulary': False}},\n  {'text': ' ',\n   'idx': 97,\n   'tag_': '_SP',\n   'pos_': 'SPACE',\n   'dep_': '',\n   'lemma_': ' ',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'The',\n   'idx': 98,\n   'tag_': 'DT',\n   'pos_': 'DET',\n   'dep_': 'det',\n   'lemma_': 'the',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'idea',\n   'idx': 102,\n   'tag_': 'NN',\n   'pos_': 'NOUN',\n   'dep_': 'nsubjpass',\n   'lemma_': 'idea',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'was',\n   'idx': 107,\n   'tag_': 'VBD',\n   'pos_': 'AUX',\n   'dep_': 'auxpass',\n   'lemma_': 'be',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'born',\n   'idx': 111,\n   'tag_': 'VBN',\n   'pos_': 'VERB',\n   'dep_': 'ROOT',\n   'lemma_': 'bear',\n   '_': {'is_in_vocabulary': False}},\n  {'text': '(',\n   'idx': 116,\n   'tag_': '-LRB-',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': '(',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'on',\n   'idx': 117,\n   'tag_': 'IN',\n   'pos_': 'ADP',\n   'dep_': 'prep',\n   'lemma_': 'on',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'the',\n   'idx': 120,\n   'tag_': 'DT',\n   'pos_': 'DET',\n   'dep_': 'det',\n   'lemma_': 'the',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'beach',\n   'idx': 124,\n   'tag_': 'NN',\n   'pos_': 'NOUN',\n   'dep_': 'pobj',\n   'lemma_': 'beach',\n   '_': {'is_in_vocabulary': False}},\n  {'text': ')',\n   'idx': 129,\n   'tag_': '-RRB-',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': ')',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'while',\n   'idx': 131,\n   'tag_': 'IN',\n   'pos_': 'SCONJ',\n   'dep_': 'mark',\n   'lemma_': 'while',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'they',\n   'idx': 137,\n   'tag_': 'PRP',\n   'pos_': 'PRON',\n   'dep_': 'nsubj',\n   'lemma_': '-PRON-',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'were',\n   'idx': 142,\n   'tag_': 'VBD',\n   'pos_': 'AUX',\n   'dep_': 'aux',\n   'lemma_': 'be',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'constructing',\n   'idx': 147,\n   'tag_': 'VBG',\n   'pos_': 'VERB',\n   'dep_': 'advcl',\n   'lemma_': 'construct',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'a',\n   'idx': 160,\n   'tag_': 'DT',\n   'pos_': 'DET',\n   'dep_': 'det',\n   'lemma_': 'a',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'website',\n   'idx': 162,\n   'tag_': 'NN',\n   'pos_': 'NOUN',\n   'dep_': 'dobj',\n   'lemma_': 'website',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'to',\n   'idx': 170,\n   'tag_': 'TO',\n   'pos_': 'PART',\n   'dep_': 'aux',\n   'lemma_': 'to',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'be',\n   'idx': 173,\n   'tag_': 'VB',\n   'pos_': 'AUX',\n   'dep_': 'advcl',\n   'lemma_': 'be',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'the',\n   'idx': 176,\n   'tag_': 'DT',\n   'pos_': 'DET',\n   'dep_': 'det',\n   'lemma_': 'the',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'basis',\n   'idx': 180,\n   'tag_': 'NN',\n   'pos_': 'NOUN',\n   'dep_': 'attr',\n   'lemma_': 'basis',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'of',\n   'idx': 186,\n   'tag_': 'IN',\n   'pos_': 'ADP',\n   'dep_': 'prep',\n   'lemma_': 'of',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'another',\n   'idx': 189,\n   'tag_': 'DT',\n   'pos_': 'DET',\n   'dep_': 'det',\n   'lemma_': 'another',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'start',\n   'idx': 197,\n   'tag_': 'VB',\n   'pos_': 'VERB',\n   'dep_': 'amod',\n   'lemma_': 'start',\n   '_': {'is_in_vocabulary': False}},\n  {'text': '-',\n   'idx': 202,\n   'tag_': 'HYPH',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': '-',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'up',\n   'idx': 203,\n   'tag_': 'RP',\n   'pos_': 'ADP',\n   'dep_': 'prt',\n   'lemma_': 'up',\n   '_': {'is_in_vocabulary': False}},\n  {'text': 'idea',\n   'idx': 206,\n   'tag_': 'NN',\n   'pos_': 'NOUN',\n   'dep_': 'pobj',\n   'lemma_': 'idea',\n   '_': {'is_in_vocabulary': False}},\n  {'text': '.',\n   'idx': 210,\n   'tag_': '.',\n   'pos_': 'PUNCT',\n   'dep_': 'punct',\n   'lemma_': '.',\n   '_': {'is_in_vocabulary': False}}],\n 'tags': ['B-ORGANIZATION',\n  'I-ORGANIZATION',\n  'L-ORGANIZATION',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'B-PERSON',\n  'L-PERSON',\n  'O',\n  'B-PERSON',\n  'L-PERSON',\n  'O',\n  'B-PERSON',\n  'L-PERSON',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O'],\n 'template_id': 117,\n 'metadata': {'Gender': 'female',\n  'NameSet': 'Swedish',\n  'Country': 'Ukraine',\n  'Lowercase': False,\n  'Template#': 117}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "input_samples[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify randomness of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0: 1\n",
      "1: 1\n",
      "3: 1\n",
      "4: 1\n",
      "5: 1\n",
      "7: 1\n",
      "9: 2\n",
      "10: 1\n",
      "11: 1\n",
      "15: 1\n",
      "18: 2\n",
      "19: 1\n",
      "20: 1\n",
      "22: 2\n",
      "23: 2\n",
      "24: 1\n",
      "25: 1\n",
      "29: 1\n",
      "30: 1\n",
      "32: 1\n",
      "35: 2\n",
      "38: 3\n",
      "39: 2\n",
      "40: 1\n",
      "42: 2\n",
      "44: 1\n",
      "47: 3\n",
      "50: 1\n",
      "53: 1\n",
      "56: 1\n",
      "59: 1\n",
      "61: 1\n",
      "63: 2\n",
      "64: 2\n",
      "67: 3\n",
      "70: 1\n",
      "71: 1\n",
      "72: 2\n",
      "74: 1\n",
      "75: 2\n",
      "77: 1\n",
      "78: 1\n",
      "79: 2\n",
      "80: 1\n",
      "82: 2\n",
      "83: 1\n",
      "84: 1\n",
      "86: 1\n",
      "87: 1\n",
      "89: 3\n",
      "90: 1\n",
      "91: 2\n",
      "92: 2\n",
      "94: 2\n",
      "95: 1\n",
      "97: 2\n",
      "98: 1\n",
      "102: 2\n",
      "103: 1\n",
      "107: 1\n",
      "108: 1\n",
      "109: 1\n",
      "111: 1\n",
      "114: 1\n",
      "116: 1\n",
      "117: 2\n",
      "119: 2\n",
      "120: 1\n",
      "122: 1\n",
      "124: 1\n",
      "125: 2\n",
      "100\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count_per_template_id = Counter([sample.metadata['Template#'] for sample in input_samples])\n",
    "for key in sorted(count_per_template_id):\n",
    "    print(\"{}: {}\".format(key,count_per_template_id[key]))\n",
    "    \n",
    "print(sum(count_per_template_id.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to the CONLL structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    text    pos   tag  Template#  gender  country  label  sentence\n0    Stm  PROPN   NNP        117  female  Ukraine  B-ORG         0\n1   Auto  PROPN   NNP        117  female  Ukraine  I-ORG         0\n2  Parts  PROPN  NNPS        117  female  Ukraine  I-ORG         0\n3     is    AUX   VBZ        117  female  Ukraine      O         0\n4    the    DET    DT        117  female  Ukraine      O         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>pos</th>\n      <th>tag</th>\n      <th>Template#</th>\n      <th>gender</th>\n      <th>country</th>\n      <th>label</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stm</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>117</td>\n      <td>female</td>\n      <td>Ukraine</td>\n      <td>B-ORG</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Auto</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>117</td>\n      <td>female</td>\n      <td>Ukraine</td>\n      <td>I-ORG</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Parts</td>\n      <td>PROPN</td>\n      <td>NNPS</td>\n      <td>117</td>\n      <td>female</td>\n      <td>Ukraine</td>\n      <td>I-ORG</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>AUX</td>\n      <td>VBZ</td>\n      <td>117</td>\n      <td>female</td>\n      <td>Ukraine</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the</td>\n      <td>DET</td>\n      <td>DT</td>\n      <td>117</td>\n      <td>female</td>\n      <td>Ukraine</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "from presidio_evaluator import InputSample\n",
    "\n",
    "conll = InputSample.create_conll_dataset(input_samples)\n",
    "conll.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright notice:\n",
    "\n",
    "\n",
    "Data generated for evaluation was created using Fake Name Generator.\n",
    "\n",
    "Fake Name Generator identities by the [Fake Name Generator](https://www.fakenamegenerator.com/) \n",
    "are licensed under a [Creative Commons Attribution-Share Alike 3.0 United States License](http://creativecommons.org/licenses/by-sa/3.0/us/). Fake Name Generator and the Fake Name Generator logo are trademarks of Corban Works, LLC.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}